{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTTuiXriCpuZ"
      },
      "outputs": [],
      "source": [
        "# importing essential libraries for data analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.options.display.max_columns = None\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu3FeqdlCpua"
      },
      "outputs": [],
      "source": [
        "# import dataset and take a brief look of the dataset\n",
        "df = pd.read_csv('/content/sample_data/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UPvNCOeCpua"
      },
      "outputs": [],
      "source": [
        "# helper function to get shape of the dataset\n",
        "def get_shape(df):\n",
        "    print('Now there are', df.shape[0], 'rows and',df.shape[1],'columns in this dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1oI8Fk8Cpub"
      },
      "outputs": [],
      "source": [
        "# print out the shape of the dataset\n",
        "get_shape(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBTiPmFjCpub"
      },
      "outputs": [],
      "source": [
        "# count unique values of each features\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NlQ1ce5Cpub"
      },
      "outputs": [],
      "source": [
        "# check missing data for each feature\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUF6XmFlCpub"
      },
      "outputs": [],
      "source": [
        "# check datatype and other information for each feature\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TSBZmOpCpuc"
      },
      "outputs": [],
      "source": [
        "# separate features into numerical and non numerical groups\n",
        "df.columns.to_series().groupby(df.dtypes).groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "GLeovMFYCpuc"
      },
      "outputs": [],
      "source": [
        "# check statistical distribution for numerical features\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBx7ilkgCpuc"
      },
      "outputs": [],
      "source": [
        "# drop out features that give out useless information\n",
        "df = df.drop(columns = ['EmployeeNumber', 'EmployeeCount', 'StandardHours', 'Over18'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyyQFE4RCpuc"
      },
      "outputs": [],
      "source": [
        "# check distribution for target variable\n",
        "sns.countplot(x = 'Attrition', data = df);\n",
        "plt.savefig('attrition.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3joSKjhCpuc"
      },
      "source": [
        "The distribution of column 'Attrition' is quite imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K63luu54Cpuc"
      },
      "outputs": [],
      "source": [
        "# visualization for numerical features\n",
        "fig, axss = plt.subplots(3,4, figsize=[15,10])\n",
        "sns.boxplot(x='Attrition', y ='DailyRate', data=df, ax=axss[0][0],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='Age', data=df, ax=axss[0][1],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='DistanceFromHome', data=df, ax=axss[0][2],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='HourlyRate', data=df, ax=axss[0][3],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='MonthlyIncome', data=df, ax=axss[1][0],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='MonthlyRate', data=df, ax=axss[1][1],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='NumCompaniesWorked', data=df, ax=axss[1][2],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='TotalWorkingYears', data=df, ax=axss[1][3],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='YearsAtCompany', data=df, ax=axss[2][0],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='YearsInCurrentRole', data=df, ax=axss[2][1],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='YearsSinceLastPromotion', data=df, ax=axss[2][2],palette=\"Blues\")\n",
        "sns.boxplot(x='Attrition', y ='YearsWithCurrManager', data=df, ax=axss[2][3],palette=\"Blues\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('numerical_dist.png');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpfnfGQ0Cpud"
      },
      "outputs": [],
      "source": [
        "# visualization for non numerical features\n",
        "fig,axss = plt.subplots(2,4, figsize=[15,10])\n",
        "sns.countplot(x='Attrition', hue='BusinessTravel', data=df, ax=axss[0][0])\n",
        "sns.countplot(x='Attrition', hue='Department', data=df, ax=axss[0][1])\n",
        "sns.countplot(x='Attrition', hue='Gender', data=df, ax=axss[0][2])\n",
        "sns.countplot(x='Attrition', hue='JobRole', data=df, ax=axss[0][3])\n",
        "sns.countplot(x='Attrition', hue='EducationField', data=df, ax=axss[1][0])\n",
        "sns.countplot(x='Attrition', hue='MaritalStatus', data=df, ax=axss[1][1])\n",
        "sns.countplot(x='Attrition', hue='OverTime', data=df, ax=axss[1][2])\n",
        "plt.tight_layout()\n",
        "plt.savefig('cate_dist.png');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eFEgtKxCpud"
      },
      "source": [
        "#### 2. Feature engineering\n",
        "\n",
        "For feature engineering, we would like to check correlations between each features and tranform non numerical feature into numerical by different ways such as encoding so that we could be able to feed the feature to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDwFexe-Cpud"
      },
      "outputs": [],
      "source": [
        "# tranform binary feature into 0 and 1\n",
        "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "df['OverTime'] = df['OverTime'].map({'Yes': 1, 'No': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rz1Sc6aCpud"
      },
      "outputs": [],
      "source": [
        "# check correlation between numerical features and target variable\n",
        "corr_score = df[['Age', 'DailyRate', 'DistanceFromHome', 'Education',\n",
        "        'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel',\n",
        "        'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
        "        'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n",
        "        'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
        "        'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
        "        'YearsSinceLastPromotion', 'YearsWithCurrManager', 'Attrition']].corr()\n",
        "corr_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW9g2qVkCpud"
      },
      "outputs": [],
      "source": [
        "# visualization of correlation relationships\n",
        "plt.figure(figsize=(15, 10))\n",
        "mask = np.triu(corr_score)\n",
        "sns.heatmap(corr_score,cmap=\"Oranges\",annot = True, fmt = '.2f',mask = mask)\n",
        "plt.tight_layout()\n",
        "plt.savefig('corr.png');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrGgxLl1Cpud"
      },
      "outputs": [],
      "source": [
        "# Drop the target column and get a clean dataframe with features\n",
        "y = df['Attrition']\n",
        "df_clean = df.drop(columns = ['Attrition'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "EKP74QpdCpud"
      },
      "outputs": [],
      "source": [
        "# apply one hot encoding to non numerical features\n",
        "df_clean = pd.get_dummies(df_clean, columns = ['BusinessTravel', 'Gender','MaritalStatus'], drop_first = True)\n",
        "df_clean = pd.get_dummies(df_clean)\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH26LHeiCpue"
      },
      "outputs": [],
      "source": [
        "# check the columns we have after feature engineering\n",
        "print(list(df_clean.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_1ExjxwCpue"
      },
      "outputs": [],
      "source": [
        "# check the shape for the new dataset\n",
        "get_shape(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld3IoRXcCpue"
      },
      "outputs": [],
      "source": [
        "# filter out features that needs to be standarized\n",
        "col_tobe_standard = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction',\n",
        "                   'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome',\n",
        "                   'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating',\n",
        "                   'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
        "                   'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
        "                   'YearsWithCurrManager']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EhhgS_hCpue"
      },
      "outputs": [],
      "source": [
        "# standarization on numercial features so that all the numerical features are having the same type of normal distribution\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "for col in col_tobe_standard:\n",
        "    df_clean[col] = df_clean[col].astype(float)\n",
        "    df_clean[[col]] = scaler.fit_transform(df_clean[[col]])\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meOgfXL1Cpue"
      },
      "source": [
        "#### 3. Model training and performance evaluation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV0IUQl6Cpue"
      },
      "outputs": [],
      "source": [
        "# split dataset into training set and testing set with stratified sampling so that each dataset contains observations\n",
        "# for both exit and non exit employees\n",
        "from sklearn import model_selection\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_clean,\n",
        "                                                                    y,\n",
        "                                                                    test_size=0.25,\n",
        "                                                                    stratify = y)\n",
        "print('Training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
        "print('Test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd8rKt4BCpue"
      },
      "outputs": [],
      "source": [
        "# build different machine learning models with the same random state if applicable\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report,confusion_matrix,roc_curve, roc_auc_score\n",
        "\n",
        "\n",
        "lr = LogisticRegression(random_state = 6)\n",
        "knn = KNeighborsClassifier()\n",
        "rf = RandomForestClassifier(random_state = 6)\n",
        "dt = DecisionTreeClassifier(random_state = 6)\n",
        "mlp = MLPClassifier(random_state = 6)\n",
        "xg = xgb.XGBClassifier(random_state = 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLWVpwB7Cpue"
      },
      "outputs": [],
      "source": [
        "# naive approach on each models without hyperparameter tuning\n",
        "model_list = [lr,knn,rf,dt,mlp,xg]\n",
        "score_res = []\n",
        "for model in model_list:\n",
        "    draft = model_selection.cross_val_score(model, X_train, y_train, cv = 5)\n",
        "    score_res.append(draft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSnFv9IYCpuf"
      },
      "outputs": [],
      "source": [
        "# print out naive approach performance\n",
        "model_names = ['Logistic Regression', 'KNN', 'Random Forest','Decision Tree','Neural Network','XG Boost']\n",
        "idx = ['cv_1','cv_2','cv_3','cv_4','cv_5']\n",
        "df_accuracy = pd.DataFrame(np.array(score_res).T, columns = model_names, index = idx).round(decimals=3)\n",
        "print('='*60)\n",
        "print('The Score is listed below \\n\\n',df_accuracy)\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yflCxy9NCpuf"
      },
      "outputs": [],
      "source": [
        "# visualize the performance of different machine learning models\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.boxplot(data = df_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU_i7N7aCpuf"
      },
      "source": [
        "It looks like decision tree is not performaning well compared with other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpxwlt7ACpuf"
      },
      "outputs": [],
      "source": [
        "# helper function to get best parameters from best model after grid search cross validation\n",
        "best_models = []\n",
        "def get_grid_res(gs):\n",
        "    print(\"Best Score:\", \"{:.3f}\".format(gs.best_score_))\n",
        "    print(\"Best Parameters:\")\n",
        "    best_params = gs.best_params_\n",
        "    for k, v in best_params.items():\n",
        "        print(k, \":\", v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Old1gvx6Cpul"
      },
      "outputs": [],
      "source": [
        "# set kfold number for k fold cross validation method\n",
        "kfold = model_selection.KFold(n_splits=10, random_state = 6, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2bh78axCpul"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning for logistic regression\n",
        "lr_params = {'penalty':('l1', 'l2'),\n",
        "          'C':(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6J6kl2gCpul"
      },
      "outputs": [],
      "source": [
        "# apply grid search on each hyperparameter and fit in with data\n",
        "grid_lr = GridSearchCV(lr, lr_params, cv= kfold)\n",
        "grid_lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4APh81bbCpum"
      },
      "outputs": [],
      "source": [
        "lr_res = grid_lr.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0rQv0yoCpum"
      },
      "outputs": [],
      "source": [
        "# visualize the affect of different hyperparameters on performance\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x = 'param_C', y = 'mean_test_score',hue = 'param_penalty',data = lr_res)\n",
        "plt.xlabel('Parameter C',fontsize = 15)\n",
        "plt.ylabel('Estimator',fontsize = 15)\n",
        "plt.title('GridSearch Cross Validation Result',fontsize = 15)\n",
        "plt.legend(fontsize = 15)\n",
        "plt.savefig('LR.png');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rvn1K2Y5Cpum"
      },
      "outputs": [],
      "source": [
        "# apply helper function to get the best hyperparameter\n",
        "get_grid_res(grid_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD35vsbUCpum"
      },
      "outputs": [],
      "source": [
        "best_lr_model = grid_lr.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tRnBZhRCpum"
      },
      "outputs": [],
      "source": [
        "# append the best model to the list for other evalution\n",
        "best_models.append(('Logistic Regression', best_lr_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEnbi6D0Cpum"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning for K nearest neighbors\n",
        "knn_params = {\n",
        "    'n_neighbors':[3,5,7,9,11,13,15,17,21,31,59,61,63]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBAbiQP1Cpum"
      },
      "outputs": [],
      "source": [
        "# apply grid search on each hyperparameter and fit in with data\n",
        "grid_knn = GridSearchCV(knn, knn_params, cv= kfold)\n",
        "grid_knn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChMi0W28Cpum"
      },
      "outputs": [],
      "source": [
        "knn_res = grid_knn.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXZKwDhQCpun"
      },
      "outputs": [],
      "source": [
        "# visualize the affect of different hyperparameters on performance\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x = 'param_n_neighbors', y = 'mean_test_score',data = knn_res)\n",
        "plt.xlabel('Parameter K',fontsize = 15)\n",
        "plt.ylabel('Estimator',fontsize = 15)\n",
        "plt.title('GridSearch Cross Validation Result',fontsize = 15)\n",
        "plt.savefig('knn.png');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jek51c2Cpun"
      },
      "outputs": [],
      "source": [
        "# apply helper function to get the best hyperparameter\n",
        "get_grid_res(grid_knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9DylIUqCpun"
      },
      "outputs": [],
      "source": [
        "best_knn_model = grid_knn.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZyNNFZICpun"
      },
      "outputs": [],
      "source": [
        "# append the best model to the list for other evalution\n",
        "best_models.append(('K Nearest Neighbors',best_knn_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Fh_J9CCpun"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning for random forest\n",
        "params_rf = {\n",
        "    'n_estimators': [20,40,60,80],\n",
        "    'min_samples_split':[4,6,8],\n",
        "    'max_depth': [1, 5, 10, 15],\n",
        "    'max_features': ['sqrt', 'auto','log2']\n",
        "}\n",
        "grid_rf = GridSearchCV(rf,params_rf, cv=kfold)\n",
        "grid_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdEnEvToCpun"
      },
      "outputs": [],
      "source": [
        "# apply helper function to get the best hyperparameter\n",
        "get_grid_res(grid_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgqmV0MzCpun"
      },
      "outputs": [],
      "source": [
        "rf_res = grid_rf.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qk_ubezCpuo"
      },
      "outputs": [],
      "source": [
        "best_rf_model = grid_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ITvZ7rOCpuo"
      },
      "outputs": [],
      "source": [
        "# append the best model to the list for other evalution\n",
        "best_models.append(('Random Forest', best_rf_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5q3KU0hCpuo"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning for decision tree\n",
        "params_dt = {\n",
        "    'max_depth':[1,5,10,15],\n",
        "    'min_samples_split':[2,4,6,8,10]\n",
        "}\n",
        "grid_dt = GridSearchCV(dt,params_dt, cv=kfold)\n",
        "grid_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hVtGmP_Cpuo"
      },
      "outputs": [],
      "source": [
        "# apply helper function to get the best hyperparameter\n",
        "get_grid_res(grid_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXoMNGMkCpuo"
      },
      "outputs": [],
      "source": [
        "best_dt_model = grid_dt.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4rmbqKgCpuo"
      },
      "outputs": [],
      "source": [
        "# append the best model to the list for other evalution\n",
        "best_models.append(('Decision Tree', best_dt_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQQ3_gjHCpuo"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning for multi layer perceptrons\n",
        "params_mlp = {\n",
        "    'hidden_layer_sizes': [(10,),(20,),(30,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'alpha': [0.001, 0.01, 0.1]\n",
        "}\n",
        "grid_mlp = GridSearchCV(mlp,params_mlp, cv = kfold)\n",
        "grid_mlp.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmSQLPmfCpuo"
      },
      "outputs": [],
      "source": [
        "# apply helper function to get the best hyperparameter\n",
        "get_grid_res(grid_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SZL1fcZCpup"
      },
      "outputs": [],
      "source": [
        "best_mlp_model = grid_mlp.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BWKXTZlCpup"
      },
      "outputs": [],
      "source": [
        "# append the best model to the list for other evalution\n",
        "best_models.append(('Neural Network', best_mlp_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWbobgtpCpup"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning for extreme boosting tree aka xgboost\n",
        "params_xgb = {\n",
        "        'subsample': [0.4, 0.6, 0.8],\n",
        "        'max_depth': [1,5,10,15],\n",
        "        'n_estimators':[40,60,80],\n",
        "        'reg_alpha':[0.01, 0.05, 0.1, 0.5, 1, 5],\n",
        "        'reg_lambda':[0.01, 0.05, 0.1, 0.5, 1, 5],\n",
        "        'eta':[0.4,0.6,0.8],\n",
        "        'learning_rate':[0.1, 0.3, 0.5]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RAs4AUbCpup"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "grid_xgb = RandomizedSearchCV(xg, params_xgb,cv = kfold,n_iter = 50)\n",
        "grid_xgb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZrV23DkCpup"
      },
      "outputs": [],
      "source": [
        "# apply helper function to get the best hyperparameter\n",
        "get_grid_res(grid_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYnuWEyHCpup"
      },
      "outputs": [],
      "source": [
        "best_xgb_model = grid_xgb.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzjXYIU0Cpup"
      },
      "outputs": [],
      "source": [
        "# append the best model to the list for other evalution\n",
        "best_models.append(('Extreme Boosting Tree', best_xgb_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG1YBWTJCpuq"
      },
      "outputs": [],
      "source": [
        "# print out the list of optimized models\n",
        "for name,model in best_models:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVhz9jSxCpuq"
      },
      "outputs": [],
      "source": [
        "# helper function to print out and visualize the evaluation result of each model including\n",
        "# confusion matrix, precison-recall and f1 score\n",
        "def plot_cm(models):\n",
        "    sns.set_style('white')\n",
        "    class_names = ['No','Yes']\n",
        "    for model_name, model in models:\n",
        "        cm = confusion_matrix(y_test,model.predict(X_test))\n",
        "        tn = cm[0][0]\n",
        "        fp = cm[0][1]\n",
        "        fn = cm[1][0]\n",
        "        tp = cm[1][1]\n",
        "        accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
        "        precision = tp / (tp + fp + 0.0)\n",
        "        recall = tp / (tp + fn + 0.0)\n",
        "        f1 = 2 / (( 1 / precision) + ( 1 / recall))\n",
        "        plot_confusion_matrix(model, X_test, y_test,\n",
        "                              display_labels=class_names,\n",
        "                              cmap=\"Oranges\")\n",
        "        plt.title(model_name, fontsize = 15)\n",
        "        plt.ylabel('Actual',fontsize = 15)\n",
        "        plt.xlabel('Predicted\\nAccuracy = {}\\nPrecision = {}\\nRecell = {}\\nF1 = {}'\n",
        "                   .format((round(accuracy, 3)),round(precision, 3),round(recall, 3),round(f1, 3)), fontsize = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "EVp9BKD5Cpuq"
      },
      "outputs": [],
      "source": [
        "plot_cm(best_models)\n",
        "plt.savefig('cm.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nW3k9KqCpuq"
      },
      "outputs": [],
      "source": [
        "# visualize ROC curve for each optimized model\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "for model_name, model in best_models:\n",
        "        yproba = model.predict_proba(X_test)[::,1]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "        auc = roc_auc_score(y_test, yproba)\n",
        "        result_table = result_table.append({'classifiers':model_name,\n",
        "                                            'fpr':fpr,\n",
        "                                            'tpr':tpr,\n",
        "                                            'auc':auc}, ignore_index=True)\n",
        "\n",
        "    # Set name of the classifiers as index labels\n",
        "result_table.set_index('classifiers', inplace=True)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'],\n",
        "             result_table.loc[i]['tpr'],\n",
        "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
        "\n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "plt.title('ROC Curve Analysis',fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "plt.savefig('ROC.png');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqFI3_iZCpuq"
      },
      "source": [
        "#### 4. Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rZrgIZTCpuq"
      },
      "outputs": [],
      "source": [
        "# helper function to visualize feature importance from random forest and LASSO\n",
        "def imp_df(column_names, importances):\n",
        "    df = pd.DataFrame({'feature': column_names,\n",
        "                       'feature_importance': importances}).sort_values('feature_importance', ascending = False)\\\n",
        "    .reset_index(drop = True)\n",
        "    return df\n",
        "\n",
        "def var_imp_plot(imp_df, title):\n",
        "    imp_df.columns = ['feature', 'feature_importance']\n",
        "    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'blue')\n",
        "    plt.title(title, fontsize = 20)\n",
        "    plt.xticks(fontsize = 15)\n",
        "    plt.yticks(fontsize = 15)\n",
        "    plt.xlabel(imp_df.columns[1], fontsize = 20)\n",
        "    plt.ylabel(imp_df.columns[0], fontsize = 20)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK2vvcacCpuq"
      },
      "outputs": [],
      "source": [
        "base_imp = imp_df(X_train.columns, best_rf_model.feature_importances_)\n",
        "plt.figure(figsize=(15, 15))\n",
        "var_imp_plot(base_imp, 'Random Forest Feature Importance')\n",
        "plt.savefig('feature_importance.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb1eRRdcCpur"
      },
      "outputs": [],
      "source": [
        "# build a LASSO model for feature selection\n",
        "from sklearn.linear_model import LassoCV\n",
        "reg = LassoCV()\n",
        "reg.fit(X_train, y_train)\n",
        "coef = pd.DataFrame(reg.coef_, index = X_train.columns)\n",
        "coef = imp_df(X_train.columns, reg.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Puaua_aLCpur"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "var_imp_plot(coef, 'LASSO Feature importance')\n",
        "plt.savefig('L1_feature_importance.png');"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}